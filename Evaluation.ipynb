{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: CLAD 23 anonymous authors\n",
    "Description: Script to evaluate the RawNet2, AASIST, Res-TSSDNet and CLAD model under manipulation attacks. Please check the configuration before testing.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml  # used by RawNet2 to read the configuration\n",
    "import json  # used to read config file\n",
    "import AASIST  # official AASIST implementation from https://github.com/clovaai/aasist/blob/main/models/AASIST.py\n",
    "import os\n",
    "import IPython.display as ipd  # used to display audio\n",
    "from tqdm import tqdm  # progress bar\n",
    "from Model import  DownStreamLinearClassifier, RawNetEncoderBaseline, RawNetBaseline, SSDNet1D  # SSDNet is the Res-TSSDNet Model\n",
    "from DatasetUtils import genSpoof_list, Dataset_ASVspoof2019_train  # ASVspoof dataset utils\n",
    "# Used to get the evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score\n",
    "from evaluate_tDCF_asvspoof19 import compute_eer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Manipulation classes used\n",
    "from DatasetUtils import VolumeChange, AddWhiteNoise, AddEnvironmentalNoise, WaveTimeStretch, AddEchoes, TimeShift, AddFade, ResampleAugmentation, pad_or_clip_batch\n",
    "import torchaudio.transforms\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Configurations\n",
    "batch_size = 32\n",
    "gpu = 1  # GPU id to use\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "# Load Config file\n",
    "with open(\"./config.conf\", \"r\") as f_json:\n",
    "    config = json.loads(f_json.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name:str, config:dict):\n",
    "    if model_name == \"RawNet2\":\n",
    "        dir_yaml = config['rawnet2_config_path']\n",
    "        with open(dir_yaml, 'r') as f_yaml:\n",
    "            parser1 = yaml.safe_load(f_yaml)\n",
    "        rawnet2_model_path = config['rawnet2_model_path']\n",
    "        rawnet2_model = RawNetBaseline(parser1['model'], device)\n",
    "        rawnet2_model = rawnet2_model.to(device)\n",
    "        rawnet2_model.load_state_dict(torch.load(rawnet2_model_path,map_location=device))\n",
    "        print('RawNetBaseline model loaded : {}'.format(rawnet2_model_path))\n",
    "        nb_params = sum([param.view(-1).size()[0] for param in rawnet2_model.parameters()])\n",
    "        print(f\"Number of Rawnet2 params:{nb_params}\")\n",
    "        return rawnet2_model\n",
    "    if model_name == \"AASIST\":\n",
    "        with open(config['aasist_config_path'], \"r\") as f_json:\n",
    "            aasist_config = json.loads(f_json.read())\n",
    "        aasist_model_config = aasist_config[\"model_config\"]\n",
    "        aasist_model = AASIST.Model(aasist_model_config).to(device)\n",
    "        nb_params = sum([param.view(-1).size()[0] for param in aasist_model.parameters()])\n",
    "        print(\"Number of AASIST params:{}\".format(nb_params))\n",
    "        aasist_model.load_state_dict(\n",
    "            torch.load(config['aasist_model_path'], map_location=device))\n",
    "        print(\"Model loaded : {}\".format(config[\"aasist_model_path\"]))\n",
    "        return aasist_model\n",
    "    if model_name == \"ResTSSDNetModel\":\n",
    "        res_tssdnet_model = SSDNet1D()\n",
    "        check_point = torch.load(config['res_tssdnet_model_path'])\n",
    "        res_tssdnet_model.load_state_dict(check_point['model_state_dict'])\n",
    "        res_tssdnet_model = res_tssdnet_model.to(device)\n",
    "        return res_tssdnet_model\n",
    "    if model_name == \"CLAD\":\n",
    "        with open(config['aasist_config_path'], \"r\") as f_json:        \n",
    "            aasist_config = json.loads(f_json.read())\n",
    "        aasist_model_config = aasist_config[\"model_config\"]\n",
    "        aasist_encoder = AASIST.AasistEncoder(aasist_model_config).to(device)\n",
    "        downstream_model = DownStreamLinearClassifier(aasist_encoder, input_depth=160)\n",
    "        checkpoint = torch.load(config['clad_model_path_for_evaluation'], map_location=device)\n",
    "        downstream_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        downstream_model = downstream_model.to(device)\n",
    "        return downstream_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the metrics, if the threshold is not given, the threshold output by the EER calculation will be used.\n",
    "def get_eval_metrics(score_save_path, plot_figure=True, given_threshold=None, print_result=True):\n",
    "    cm_data = np.genfromtxt(score_save_path, dtype=str)\n",
    "    cm_keys = cm_data[:, 2]\n",
    "    # cm_keys = 'bonafide' means 1, 'spoof' means 0\n",
    "    cm_keys = np.where(cm_keys == 'bonafide', 1, 0)\n",
    "    cm_scores = cm_data[:, 3].astype(float)\n",
    "    # Compute EER\n",
    "    # Extract bona fide (real human) and spoof scores from the CM scores\n",
    "    bona_cm = cm_scores[cm_keys == 1]\n",
    "    spoof_cm = cm_scores[cm_keys == 0]\n",
    "    eer_cm, threshold = compute_eer(bona_cm, spoof_cm)\n",
    "\n",
    "    auc = roc_auc_score(cm_keys, cm_scores)\n",
    "    if given_threshold is not None:\n",
    "        threshold = given_threshold\n",
    "    y_pred = np.where(cm_scores > threshold, 1, 0)\n",
    "    f1 = f1_score(cm_keys, y_pred)\n",
    "    acc = balanced_accuracy_score(cm_keys, y_pred)\n",
    "    # compute False Acceptance Rate and False Rejection Rate\n",
    "    FAR = np.sum(cm_keys[y_pred == 1] == 0) / np.sum(cm_keys == 0)\n",
    "    FRR = np.sum(cm_keys[y_pred == 0] == 1) / np.sum(cm_keys == 1)\n",
    "    if print_result == True:\n",
    "        print(f\"EER:{eer_cm}, auc:{auc}, F1 score:{f1}, acc:{acc}, threshold:{threshold}, FAR:{FAR}, FRR:{FRR}\")\n",
    "    if plot_figure == True:\n",
    "        # ylgnbu_pal = sns.color_palette(\"YlGnBu\", as_cmap=True)\n",
    "        sns.histplot(bona_cm, kde=False, label='Real', stat=\"density\", element=\"step\", fill=False, bins='auto')\n",
    "        sns.histplot(spoof_cm, kde=False, label='Deepfake', stat=\"density\",element=\"step\", fill=False, bins='auto')\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlabel('Prediction score')\n",
    "        plt.title('Prediction score histogram')\n",
    "    return (eer_cm, auc, f1, acc, threshold, FAR, FRR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_19_LA_eval(model, score_save_path, model_name, database_path, augmentations=None , batch_size = 1024, cut_length = 64600):\n",
    "    # In asvspoof dataset, label = 1 means bonafide.\n",
    "    model.eval()\n",
    "    device = \"cuda\"\n",
    "    # load asvspoof 2019 LA eval dataset\n",
    "    d_label_trn, file_eval = genSpoof_list(dir_meta=database_path+\"ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\", is_train=False, is_eval=False)\n",
    "    print('no. of ASVspoof 2019 LA evaluating trials', len(file_eval))\n",
    "    asvspoof_LA_eval_dataset = Dataset_ASVspoof2019_train(list_IDs=file_eval, labels=d_label_trn, base_dir=os.path.join(\n",
    "        database_path+'ASVspoof2019_LA_eval/'), cut_length=cut_length)\n",
    "    asvspoof_2019_LA_eval_dataloader = DataLoader(asvspoof_LA_eval_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=8, pin_memory=True)  # added num_workders param to speed up.\n",
    "    with open(score_save_path, 'w') as file:  # This creates an empty file or empties an existing file\n",
    "        pass\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (audio_input,labels) in enumerate(tqdm(asvspoof_2019_LA_eval_dataloader)):\n",
    "            score_list = []  \n",
    "            # audio_input = torch.squeeze(audio_input)\n",
    "            audio_input = audio_input.squeeze(1)          \n",
    "            audio_input = audio_input.to(device)\n",
    "\n",
    "            if augmentations != None:\n",
    "                # note that some manipulation will change the length of the audio, so we need to clip or pad it to the same length\n",
    "                audio_length = audio_input.shape[-1]\n",
    "                # only apply the augmentation on the spoofed audio, and pad or clip it to the same length\n",
    "                audio_input[labels==0] = pad_or_clip_batch(augmentations(audio_input[labels==0]), audio_length, random_clip=False)\n",
    "            # check the length of the audio, if it is not the same as the cut_length, then repeat or clip it to the same length\n",
    "            if audio_input.shape[-1] < cut_length:\n",
    "                audio_input = audio_input.repeat(1, int(cut_length/audio_input.shape[-1])+1)[:, :cut_length]\n",
    "            elif audio_input.shape[-1] > cut_length:\n",
    "                audio_input = audio_input[:, :cut_length]\n",
    "            \n",
    "            if model_name == \"ResTSSDNetModel\":\n",
    "                audio_input = audio_input.unsqueeze(1)  # pretrained ResTSSDNetModel takes 3D input(batch, channel, waveform), so we need to add a dimension for channels\n",
    "            batch_out = model(audio_input)\n",
    "            if model_name == \"AASIST\":\n",
    "                batch_out = batch_out[1]  # the AASIST model output last_hidden_state and score and we only need the score\n",
    "            # The ResTSSDNetModel output two scores, but the order is reversed. So we need to reverse it back.\n",
    "            # The ResTSSDNetModel takes bonafide as 0, reference: https://github.com/ghua-ac/end-to-end-synthetic-speech-detection/blob/main/data.py#L89\n",
    "            elif model_name == \"ResTSSDNetModel\":  \n",
    "                batch_out = batch_out[:, [1,0]]\n",
    "            batch_score = (batch_out[:, 1]\n",
    "                          ).data.cpu().numpy().ravel()\n",
    "            label_list = ['bonafide' if i==1 else 'spoof' for i in labels]\n",
    "            score_list.extend(batch_score.tolist())\n",
    "\n",
    "            with open(score_save_path, 'a+') as fh:\n",
    "                for label, cm_score in zip(label_list,score_list):\n",
    "                    fh.write('- - {} {}\\n'.format(label, cm_score))\n",
    "            fh.close()   \n",
    "        print('Scores saved to {}'.format(score_save_path))\n",
    "    return  get_eval_metrics(score_save_path=score_save_path, plot_figure=False)# TODO: return EER, AUC and other things when I implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {}  # create a empty dict to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dataset_path = config['noise_dataset_path']\n",
    "manipulations = {\n",
    "    \"no_augmentation\": None,\n",
    "    \"volume_change_50\": torchaudio.transforms.Vol(gain=0.5,gain_type='amplitude'),\n",
    "    \"volume_change_10\": torchaudio.transforms.Vol(gain=0.1,gain_type='amplitude'),\n",
    "    \"white_noise_15\": AddWhiteNoise(max_snr_db = 15, min_snr_db=15),\n",
    "    \"white_noise_20\": AddWhiteNoise(max_snr_db = 20, min_snr_db=20),\n",
    "    \"white_noise_25\": AddWhiteNoise(max_snr_db = 25, min_snr_db=25),\n",
    "    \"env_noise_wind\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"wind\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_footsteps\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"footsteps\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_breathing\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"breathing\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_coughing\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"coughing\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_rain\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"rain\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_clock_tick\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"clock_tick\", noise_dataset_path=noise_dataset_path),\n",
    "    \"env_noise_sneezing\": AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"sneezing\", noise_dataset_path=noise_dataset_path),\n",
    "    \"timestretch_110\": WaveTimeStretch(max_ratio=1.10, min_ratio=1.10, n_fft=128),\n",
    "    \"timestretch_105\": WaveTimeStretch(max_ratio=1.05, min_ratio=1.05, n_fft=128),\n",
    "    \"timestretch_095\": WaveTimeStretch(max_ratio=0.95, min_ratio=0.95, n_fft=128),\n",
    "    \"timestretch_090\": WaveTimeStretch(max_ratio=0.90, min_ratio=0.90, n_fft=128),\n",
    "    \"echoes_1000_02\": AddEchoes(max_delay=1000, max_strengh=0.2, min_delay=1000, min_strength=0.2),\n",
    "    \"echoes_1000_05\": AddEchoes(max_delay=1000, max_strengh=0.5, min_delay=1000, min_strength=0.5),\n",
    "    \"echoes_2000_05\": AddEchoes(max_delay=2000, max_strengh=0.5, min_delay=2000, min_strength=0.5),\n",
    "    \"time_shift_1600\": TimeShift(max_shift=1600, min_shift=1600),\n",
    "    \"time_shift_16000\": TimeShift(max_shift=16000, min_shift=16000),\n",
    "    \"time_shift_32000\": TimeShift(max_shift=32000, min_shift=32000),\n",
    "    \"fade_50_linear\": AddFade(max_fade_size=0.5,fade_shape='linear', fix_fade_size=True),\n",
    "    \"fade_30_linear\": AddFade(max_fade_size=0.3,fade_shape='linear', fix_fade_size=True),\n",
    "    \"fade_10_linear\": AddFade(max_fade_size=0.1,fade_shape='linear', fix_fade_size=True),\n",
    "    \"fade_50_exponential\": AddFade(max_fade_size=0.5,fade_shape='exponential', fix_fade_size=True),\n",
    "    \"fade_50_quarter_sine\": AddFade(max_fade_size=0.5,fade_shape='quarter_sine', fix_fade_size=True),\n",
    "    \"fade_50_half_sine\": AddFade(max_fade_size=0.5,fade_shape='half_sine', fix_fade_size=True),\n",
    "    \"fade_50_logarithmic\": AddFade(max_fade_size=0.5,fade_shape='logarithmic', fix_fade_size=True),\n",
    "    \"resample_15000\": ResampleAugmentation([15000], device=\"cuda\"),\n",
    "    \"resample_15500\": ResampleAugmentation([15500], device=\"cuda\"),\n",
    "    \"resample_16500\": ResampleAugmentation([16500], device=\"cuda\"),\n",
    "    \"resample_17000\": ResampleAugmentation([17000], device=\"cuda\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model when the real samples are not manipulated, but the spoofed samples are manipulated.\n",
    "# for model_name in [\"AASIST\",\"RawNet2\",\"ResTSSDNetModel\",\"CLAD\"]:\n",
    "for model_name in [\"CLAD\"]:\n",
    "    if model_name == \"ResTSSDNetModel\":\n",
    "        cut_length = 96000\n",
    "    elif model_name == \"RawNet2\":\n",
    "        cut_length = 64600  # 64000 in paper. However we found it used 64600 in the implementation(https://github.com/asvspoof-challenge/2021/blob/main/LA/Baseline-RawNet2/data_utils.py) \n",
    "    else:\n",
    "        cut_length = 64600\n",
    "    manipulations[\"env_noise_wind\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"wind\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_footsteps\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"footsteps\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_breathing\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"breathing\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_coughing\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"coughing\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_rain\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"rain\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_clock_tick\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"clock_tick\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "    manipulations[\"env_noise_sneezing\"] = AddEnvironmentalNoise(max_snr_db=20, min_snr_db=20, device=\"cuda\", noise_category=\"sneezing\", noise_dataset_path=noise_dataset_path, audio_len=cut_length)\n",
    "\n",
    "    model = load_model(model_name,config)\n",
    "    for (manipulation_name, manipulation) in manipulations.items():\n",
    "        filename_prefix = model_name\n",
    "        evaluation_results[manipulation_name] = evaluation_19_LA_eval(model=model, model_name=model_name, database_path=config['database_path'], batch_size = batch_size, augmentations=manipulation, score_save_path=f\"scores/{filename_prefix}_{manipulation_name}_eval_19_LA_score.txt\", cut_length=cut_length)\n",
    "        print(f\"--------{manipulation_name} finished.--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for model_name in [\"AASIST\",\"RawNet2\",\"ResTSSDNetModel\",\"CLAD\"]:\n",
    "    results[model_name] = {}\n",
    "    # get EER threshold\n",
    "    print(\"-----Results for model:\", model_name, \"-----\")\n",
    "    results[model_name][\"no_augmentation\"] = get_eval_metrics(f\"scores/{model_name}_no_augmentation_eval_19_LA_score.txt\", plot_figure=False, print_result=False)\n",
    "    for manipulation_name in manipulations:\n",
    "        results[model_name][manipulation_name] = get_eval_metrics(f\"scores/{model_name}_{manipulation_name}_eval_19_LA_score.txt\", plot_figure=False, given_threshold=results[model_name][\"no_augmentation\"][4], print_result=False)\n",
    "        print(f\"{manipulation_name}: EER:{results[model_name][manipulation_name][0]:.2%}, AUC:{results[model_name][manipulation_name][1]:.2%}, F1 score:{results[model_name][manipulation_name][2]:.2%}, acc:{results[model_name][manipulation_name][3]:.2%}, threshold:{results[model_name][manipulation_name][4]}, FAR:{results[model_name][manipulation_name][5]:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
